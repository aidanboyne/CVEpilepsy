{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Clipping\n",
    "\n",
    "This code reads annotations from a file video_annot.txt, opens each video file, segments it into 3-second clips, and writes each clip to a separate video file in the Video_Clips directory. It also creates an annotation file vid_annotation.txt that contains the path to each clip and a label (1 or 0) indicating whether the clip contains a seizure event or not, based on the time range provided in the annotations.\n",
    "\n",
    "This may write the path with `_ '` rather than just `_` (automatically correct it with cell below) and uses `\\` instead of `/`. Find and replace the slashes in the annotation file. \n",
    "\n",
    "Finally, if you run into an error where mmmaction can't seem to find the videos, just move them into a double nested folder of the name name (for example, I put mine in `video_clips/video_clips/`)\n",
    "\n",
    "Takes around an hour to clip our dataset. Move the file created to the annotations file after completion (am not creating there to avoid overwrite on accidental run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Read frames for the current segment\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(fps \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m---> 43\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m     45\u001b[0m         segment_frames\u001b[38;5;241m.\u001b[39mappend(frame)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "input_dir = \"videos\"\n",
    "output_dir = \"video_clips\"\n",
    "annotation_file = \"uncropped_allclips_annotations.txt\"\n",
    "master_file = \"annotations/video_annotations.txt\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the annotation file for writing\n",
    "with open(annotation_file, \"a+\") as f:\n",
    "    # Read the annotations from the master file\n",
    "    with open(master_file, \"r\") as annot_file:\n",
    "        annotations = [eval(line.strip()) for line in annot_file]\n",
    "\n",
    "    # Iterate over each video file and its annotations\n",
    "    for video_path, video_id, patient_id, time_range in tqdm(annotations):\n",
    "        # Open the video file and get the properties\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Calculate the number of 3-second segments\n",
    "        num_segments = int(total_frames // (fps * 3))\n",
    "\n",
    "        # Initialize the segment counter\n",
    "        segment_count = 0\n",
    "\n",
    "        # Iterate over the segments\n",
    "        for i in range(num_segments):\n",
    "            # Set the starting frame for the current segment\n",
    "            start_frame = int(i * fps * 3)\n",
    "\n",
    "            # Set the video position to the starting frame\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "            # Initialize the frames list for the current segment\n",
    "            segment_frames = []\n",
    "\n",
    "            # Read frames for the current segment\n",
    "            for _ in range(int(fps * 3)):\n",
    "                ret, frame = video.read()\n",
    "                if ret:\n",
    "                    segment_frames.append(frame)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # If frames were successfully read for the segment\n",
    "            if len(segment_frames) > 0:\n",
    "                # Create the output segment path with patient_id\n",
    "                segment_name = f\"{patient_id}_{video_id}_Seg_{segment_count}.mp4\"\n",
    "                segment_path = os.path.join(output_dir, segment_name)\n",
    "\n",
    "                # Write the segment frames to the output video file\n",
    "                out = cv2.VideoWriter(segment_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (frame.shape[1], frame.shape[0]))\n",
    "                for frame in segment_frames:\n",
    "                    out.write(frame)\n",
    "                out.release()\n",
    "\n",
    "                # Calculate the segment start and end times in seconds\n",
    "                segment_start_time = i * 3\n",
    "                segment_end_time = (i + 1) * 3\n",
    "\n",
    "                # Check if the current segment overlaps with any seizure time\n",
    "                is_seizure = segment_start_time >= time_range[0] and segment_end_time <= time_range[1]\n",
    "\n",
    "                # Write the annotation for the current segment\n",
    "                annotation = f\"{segment_path} {1 if is_seizure else 0}\\n\"\n",
    "                f.write(annotation)\n",
    "\n",
    "                # Increment the segment counter\n",
    "                segment_count += 1\n",
    "\n",
    "        # Release the video capture\n",
    "        video.release()\n",
    "\n",
    "print(\"Video segmentation and annotation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to rename all erroneous video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"C:/Users/u251245/CVEpilepsy_remote/video_clips/video_clips/\"\n",
    "\n",
    "# Set the text to find and replace\n",
    "find_text = \"_ '\"\n",
    "replace_text = \"_\"\n",
    "\n",
    "for filename in os.listdir(dir_path):\n",
    "    file_path = os.path.join(dir_path, filename)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        # Check if the file name contains the text to find\n",
    "        if find_text in filename:\n",
    "            # Construct the new file name\n",
    "            new_filename = filename.replace(find_text, replace_text)\n",
    "            new_file_path = os.path.join(dir_path, new_filename)\n",
    "            \n",
    "            # Rename the file\n",
    "            os.rename(file_path, new_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
